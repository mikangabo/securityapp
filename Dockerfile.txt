# Use CentOS Stream 8
FROM quay.io/centos/centos:stream8

# Install required packages
RUN dnf install -y java-11-openjdk wget curl tar python3 python3-pip && \
    dnf clean all

# Set environment variables
ENV SPARK_VERSION=3.3.2
ENV HADOOP_VERSION=3.3.4
ENV SPARK_HOME=/opt/spark
ENV HADOOP_HOME=/opt/hadoop
ENV PATH="$SPARK_HOME/bin:$HADOOP_HOME/bin:$PATH"
ENV LD_LIBRARY_PATH=$HADOOP_HOME/lib/native:$LD_LIBRARY_PATH

# Download and install Apache Spark
RUN curl -L --retry 5 --retry-delay 10 -o /tmp/spark.tgz \
    https://archive.apache.org/dist/spark/spark-$SPARK_VERSION/spark-$SPARK_VERSION-bin-hadoop3.tgz && \
    tar -xvzf /tmp/spark.tgz -C /opt/ && \
    mv /opt/spark-$SPARK_VERSION-bin-hadoop3 $SPARK_HOME && \
    rm /tmp/spark.tgz

# Set working directory
WORKDIR /app

# Copy the application files
COPY refactored.py /app/refactored.py

# Ensure correct file format
RUN dos2unix /app/refactored.py || true  # Ignore errors if dos2unix is missing

# Install Python dependencies
RUN pip3 install pyspark pandas

# Run the script
CMD ["python3", "/app/refactored.py"]
